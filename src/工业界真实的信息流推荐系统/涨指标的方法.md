# 涨指标的方法

<!-- toc -->

# 概述

这节课和后面的几节课的内容是推荐系统涨指标的方法。这节课先回顾推荐系统的评价指标，尤其是LT7和LT30。后面的课程会分为5部分：  
1. 改进召回模型和添加新的召回模型。  
2. 改进粗排和精排模型。  
3. 提升召回、粗排、精排中的多样性。  
4. 特殊对待新用户、低活用户等特殊人群。  
5. 利用关注、转发、评论这三种交互行为来提升指标。  
  
课件链接： https://github.com/wangshusen/RecommenderSystem  
  
参考文献： https://arxiv.org/abs/2308.01204

## 推荐系统的评价指标

在推荐系统中，日活跃用户数（DAU）和用户留存率是最为关键的指标。目前，工业界普遍使用LT7（7天留存率）和LT30（30天留存率）来衡量用户留存情况。

例如，如果某用户在今天（t0）登录APP，并且在接下来的7天（t0～t6）中有4天再次登录，那么该用户的LT7为4。显然，LT7的范围是1≤LT7≤7，而LT30的范围是1≤LT30≤30。

LT的增长通常表明用户体验的提升，除非在LT增长的同时DAU下降。

如果APP禁止低活跃用户登录，可能会导致DAU下降，但LT却可能增长。

其他核心指标包括用户使用时长、总阅读量（即总点击数）和总曝光量。这些指标的重要性相对DAU和留存率较低。

此外，使用时长的增加通常会伴随LT的增长，但在某些情况下，时长的增加可能导致阅读量和曝光量的下降。

一些非核心指标如点击率和交互率等也可以提供辅助信息。

对于用户生成内容（UGC）平台而言，发布量和发布渗透率同样是核心指标。

## 涨指标的方法有哪些？

1. 改进召回模型，添加新的召回模型
2. 改进粗排和精排模型
3. 提升召回、粗排、精排中的多样性
4. 特殊对待新用户、低活用户等特殊人群
5. 利用关注、转发、评论这三种交互行为

# 召回

这节课的内容是推荐系统涨指标的方法。具体讲解如何通过改进召回模型（retrieval models）来提升推荐系统的核心指标。这节课的内容分三部分：双塔模型、Item-to-Item (I2I)、还有小众的召回模型（比如PDN、Deep Retrieval、SINE、M2GRL）。  
  
参考文献  
[1] Li et al. Path-based Deep Network for Candidate Item Matching in Recommenders. In SIGIR, 2021.  
[2] Gao et al. Learning an end-to-end structure for retrieval in large-scale recommendations. In CIKM, 2021.  
[3] Tan et al. Sparse-interest network for sequential recommendation. In WSDM, 2021.  
[4] Wang et al. M2GRL: A multitask multi-view graph representation learning framework for web-scale recommender systems. In KDD, 2020.  
  
课件链接： https://github.com/wangshusen/RecommenderSystem  
  
参考文献： https://arxiv.org/abs/2308.01204

## 召回模型&召回通道

推荐系统有几十条召回通道，它们的召回总量是固定的。

召回总量越大，指标越好，粗排计算量越大。

双塔模型（two-tower）和item-to-item（I2I）是最重要的两类召回模型，占据召回的大部分配额。

有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标。

有很多内容池，比如30天物品、1天物品、6小时物品、新用户优质内容池、分人群内容池。

同一个模型可以用于多个内容池，得到多条召回通道。

## 双塔模型

方向1：优化正样本、负样本。

- 简单正样本：有点击的（用户，物品）二元组
- 简单负样本：随机组合的（用户，物品）二元组
- 困难负样本：排序靠后的（用户，物品）二元组

方向2：改进神经网络结构

- Baseline：用户塔、物品塔分别是全连接网络，各输出一个向量分别作为用户、物品的表征。
- 改进：用户塔、物品塔分别用DCN代替全连接网络
- 改进：在用户塔中使用用户行为序列（last-n）
- 改进：使用多向量模型代替单向量模型。（标准的双塔模型也叫单向量模型。）

方向3：改进模型的训练方法

- Baseline：做二分类，让模型学会区分正样本和负样本
- 改进：结合二分类、batch 内负采样。（对于 batch 内负采样，需要做纠偏。)
- 改进：使用自监督学习方法；让冷门物品的embedding 学得更好。

## Item2Item模型

I2I是一大类模型，基于相似物品做召回。最常见的用法是U2I2I(user →item →item）。

如何计算物品相似度？

方法1：ItemCF 及其变体

- 一些用户同时喜欢物品$i_1$和$i_2$则认为$i_1$ 和$i_2$相似。
- ItemCF、Online ItemCF、Swing 、Online Swing 都是基于相同的思想。
- 线上同时使用上述4种I2I模型，各分配一定配额。

方法2：基于物品向量表征，计算向量相似度。（双塔模型、图神经网络均可计算物品向量表征。)
## 小众的召回模型

类似 I2I 的模型：
- U2U2I(user→user→item）：已知用户u1 与u2 相似且 u2 喜欢物品i，那么给用户 u 推荐物品i。
- U2A2I(user →author →item）：已知用户 u 喜欢作者 a  且a发布物品i，那么给用户u推荐物品i。
- U2A2A2I (user →author → author →item):已知用户 u 喜欢作者a1且a1 与a2 相似，a2 发布物品i，那么给用户u推荐物品i。

更复杂的模型：

- Path-based Deep Network (PDN) [1]
- Deep Retrieval [2]
- Sparse-Interest Network (SINE) [3]
- Multi-task Multi-view Graph Representation Learning (M2GRL) [4] 

参考文献
1. Li et al. Path-based Deep Network for Candidate Item Matching in Recommenders. In SIGlR, 2021. 
2. Gao et al. Learning an end-to-end structure for retrieval in large-scale recommendations. In ClKM,2021.
3. Tan et al. Sparse-interest network for sequential recommendation. In WSDM, 2021.
4. Wang et al. M2GRL: A multitask multi-view graph representation learning framework for web-scale recommender systems. In KDD, 2020.

## 总结：改进召回模型

双塔模型：优化正负样本、改进神经网络结构、改进训练的方法。

I2I 模型：同时使用 ItemCF及其变体、使用物品向量表征计算物品相似度。

添加小众的召回模型，比如PDN、Deep Retrieval、SINE、M2GRL等模型。

在召回总量不变的前提下，调整各召回通道的配额。（可以让各用户群体用不同的配额。）

# 排序模型

这节课的内容是通过改进粗排和精排模型涨指标。这节课的内容分5部分：  
1. 精排模型的改进  
2. 粗排模型的改进  
3. 用户行为序列建模  
4. 在线学习  
5. 老汤模型

## 精排模型的改进

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250228102611.png)

### 精排模型：基座

基座的输入包括离散特征和连续特征，输出一个向量，作为多目标预估的输入。

改进1：基座加宽加深，计算量更大，预测更准确。

改进2：做自动的特征交叉，比如bilinear[1]和LHUC[2]

改进3：特征工程，比如添加统计特征、多模态内容特征。

参考文献
1. Huang et al. FiBiNET: combining feature importance and bilinear feature interaction for click-through rate prediction. In RecSys, 2019.
2. Swietojanski et al. Learning hidden unit contributions for unsupervised acoustic model adaptation. In WSDM, 2016.

### 精排模型：多目标预估

基于基座输出的向量，同时预估点击率等多个目标。

改进1：增加新的预估目标，并把预估结果加入融合公式。

- 最标准的目标包括点击率、点赞率、收藏率、转发率、评论率、关注率、完播率······
- 寻找更多目标，比如进入评论区、给他人写的评论点赞·······
- 把新的预估目标加入融合公式

改进2：MMoE[1]、PLE[2] 等结构可能有效但往往无效。

改进3：纠正position bias[3]可能有效，也可能无效。

参考文献
1. Ma et al. Modeling task relationships in multi-task learning with multi-gate mixture-of-experts. In KDD, 2018.
2. Tang et al. Progressive layered extraction (PLE): A novel multi-task learning (MTL) model for personalized recommendations. In RecSys, 2020.
3. Zhou et al. Recommending what video to watch next: a multitask ranking system. In RecSys, 2019.
## 粗排模型的改进

### 粗排模型

粗排的打分量比精排大10倍，因此粗排模型必须够快。

简单模型：多向量双塔模型，同时预估点击率等多个目标。

复杂模型：三塔模型[1]效果好，但工程实现难度较大。

参考文献
1. Wang et al. COLD: towards the next generation of pre-ranking system. arXiv, 2020.

### 粗精排一致性建模

蒸馏精排训练粗排，让粗排与精排更一致。

优点：粗精排一致性建模可以提升核心指标。

缺点：如果精排出bug，精排预估值p有偏，会污染粗排训练数据。

方法1：pointwise 蒸馏。

设y是用户真实行为，设p是精排的预估。用$\frac{y+p}{2}$作为粗排拟合的目标。例：对于点击率目标，用户有点击（y= 1），精排预估p=0.6。用$\frac{y+p}{2}=0.8$作为粗排拟合的点击率目标。

方法2：pairwise 或listwise 蒸馏。

给定k个候选物品，按照精排预估做排序。做learning to rank(LTR），让粗排拟合物品的序（而非值）。

例：对于物品i和j，精排预估点击率为$p_i > p_j$。

LTR 鼓励粗排预估点击率满足$q_i \gt q_j$否则有惩罚。

LTR 通常使用 pairwise logistic loss。

## 用户行为序列建模

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250228104138.png)

### 用户行为序列建模方式

最简单的方法是对物品向量取平均，作为一种用户特征[1]。

DIN[2]使用注意力机制，对物品向量做加权平均。

工业界目前沿着SIM[3]的方向发展。先用类目等属性筛选物品，然后用DIN对物品向量做加权平均。

参考文献
1. Covington, Adams, and Sargin. Deep neural networks for YouTube recommendations. In RecSys, 2016.
2. Zhou et al. Deep interest network for click-through rate prediction. In KDD, 2018.
3. Qi et al. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction. In CIKM, 2020.

### 改进

改进1：增加序列长度，让预测更准确，但是会增加计算成本和推理时间。

改进2：筛选的方法，比如用类目、物品向量表征聚类。

- 离线用多模态神经网络提取物品内容特征，将物品表征为向量。
- 离线将物品向量聚为1000类，每个物品有一个聚类序号。
- 线上排序时，用户行为序列中有n=1,000,000个物品。某候选物品的聚类序号是70，对n个物品做筛选，只保留聚类序号为70的物品。n个物品中只有数千个被保留下来。
- 同时有好几种筛选方法，取筛选结果的并集。

改进3：对用户行为序列中的物品，使用ID以外的一些特征

概括：沿着SIM的方向发展，让原始的序列尽量长，然后做筛选降低序列长度，最后将筛选结果输入DIN。

## 在线学习

![全量更新和在线更新](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250228104814.png)

### 在线学习的资源消耗

既需要在凌晨做全量更新，也需要全天不间断做增量更新。

设在线学习需要 10,000 CPU core 的算力增量更新一个精排模型。推荐系统一共需要多少额外的算力给在线学习？

为了做AB测试，线上同时运行多个不同的模型。如果线上有m个模型，则需要m套在线学习的机器。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250228105040.png)

线上有 m个模型，其中1个是holdout，1个是推全的模型，m-2个测试的新模型。

每套在线学习的机器成本都很大，因此m数量很小，制约模型开发迭代的效率。

在线学习对指标的提升巨大，但是会制约模型开发迭代的效率。

## 老汤模型

用每天新产生的数据对模型做 1 epoch 的训练。久而久之，老模型训练得非常好，很难被超过。对模型做改进，重新训练，很难追上老模型。

两大问题：

问题1：如何快速判断新模型结构是否优于老模型？（不需要追上线上的老模型，只需要判断新老模型谁的结构更优。）

问题2：如何更快追平、超过线上的老模型？（只有几十天的数据，新模型就能追上训练上百天的老模型。)

问题1：如何快速判断新模型结构是否优于老模型？
- 对于新老模型结构，都随机初始化模型全连接层。
- Embedding层可以是随机初始化，也可以是复用老模型训练好的参数。
- 用n天的数据训练新老模型。（从旧到新，训练 1 epoch）。
- 如果新模型显著优于老模型，新模型很可能更优。
- 只是比较新老模型结构谁更好，而非真正追平老模型。

问题2：如何更快追平线上的老模型？

已经得出初步结论，认为新模型很可能优于老模型。用几十天的数据训练新模型，早日追平老模型。

- 方法1：尽可能多地复用老模型训练好的embedding 层，避免随机初始化 embedding 层。（Embedding 层是对用户、物品特点的“记忆”，比全连接层学得慢。）
- 方法2：把老模型作为 teacher 蒸馏新模型。（用户真实行为为y，老模型的预测是p，用$\frac{y+p}{2}$作为训练新模型的目标。

## 总结：改进排序模型

精排模型：改进模型基座（加宽加深、特征交叉、特征工程），改进多目标预估（增加新目标、MMoE、position bias）。

粗排模型：三塔模型（取代多向量双塔模型），粗精排一致性建模。

用户行为序列建模：沿着SIM的方向迭代升级，加长序列长度，改进筛选物品的方法。

在线学习：对指标提升大，但是会降低模型迭代升级效率。

老汤模型制约模型迭代升级效率，需要特殊技巧。

# 多样性

这节课的内容是通过提升推荐物品的多样性为推荐系统涨指标。在召回、粗排、精排三个阶段，均有提升多样性的方法。在召回阶段，可以通过添加噪声、随机选取用户行为序列等方式提升双塔模型、I2I的多样性。在排序阶段，结合兴趣分数与多样性分数共同给候选物品排序。

## 精排多样性

精排阶段，结合兴趣分数和多样性分数对物品$i$排序。

- $s_i$：兴趣分数，即融合点击率等多个预估目标。
- $d_i$：多样性分数，即物品$i$与已经选中的物品的差异。
- 用 $s_i +d_i$对物品做排序。

常用MMR、DPP等方法计算多样性分数，精排使用滑动窗口，粗排不使用滑动窗口。

- 精排决定最终的曝光，曝光页面上邻近的物品相似度应该小。所以计算精排多样性要使用滑动窗口。
- 粗排要考虑整体的多样性，而非一个滑动窗口中的多样性。

除了多样性分数，精排还使用打散策略增加多样性。

- 类目：当前选中物品$i$，之后5个位置不允许跟$i$的二级类目相同。
- 多模态：事先计算物品多模态内容向量表征，将全库物品聚为1000类；在精排阶段，如果当前选中物品$i$，之后10个位置不允许跟i同属一个聚类。

## 粗排多样性

粗排给5000个物品打分，选出500个物品送入精排。

提升粗排和精排多样性都可以提升推荐系统核心指标。

根据$s_i$对5000个物品排序，分数最高的200个物品送入精排。

对于剩余的4800个物品，对每个物品i计算兴趣分数$s_i$和多样性分数$d_i$。

根据$s_i+d_i$对剩余4800个物品排序，分数最高的300个物品送入精排。

## 双塔模型
### 双塔模型：添加噪声

用户塔将用户特征作为输入，输出用户的向量表征；然后做ANN检索，召回向量相似度高的物品。

线上做召回时（在计算出用户向量之后，在做ANN检索之前）往用户向量中添加随机噪声。

用户的兴趣越窄（比如用户最近交互的n个物品只覆盖少数几个类目），则添加的噪声越强。

添加噪声使得召回的物品更多样，可以提升推荐系统核心指标

### 双塔模型：抽样用户行为序列

用户最近交互的n个物品（用户行为序列）是用户塔的输入。保留最近的r个物品（$r \lt \lt n$）。从剩余的$n-r$个物品中随机抽样$t$个物品（$t\lt \lt n$）。（可以是均匀抽样，也可以用非均匀抽样让类目平衡。）将得到的$r+t$个物品作为用户行为序列，而不是用全部$n$个物品。

抽样用户行为序列为什么能涨指标？

一方面，注入随机性，召回结果更多样化。另一方面，$n$可以非常大，可以利用到用户很久之前的兴趣。

## U2I2I：抽样用户行为序列

U2I2I（user—>item一>item）中的第一个item 是指用户最近交互的n个物品之一，在U2I2I中叫作种子物品。

n个物品覆盖的类目数较少，且类目不平衡。
- 系统共有 200个类目，某用户的n个物品只覆盖15个类目。
- 足球类目的物品有 0.4n个，电视剧类目的物品有 0.2n个；其余类目的物品数均少于 0.05n个。

做非均匀随机抽样，从n个物品中选出t个，让类目平衡。(想法和效果与双塔中的用户行为序列抽样相似。)

用抽样得到的t个物品（代替原本的n个物品）作为U2I2I 的种子物品。一方面，类目更平衡，多样性更好。另一方面，n可以更大，覆盖的类目更多。
## 探索流量

每个用户曝光的物品中有2%是非个性化的，用作兴趣探索。

维护一个精选内容池，其中物品均为交互率指标高的优质物品。（内容池可以分人群，比如30~40岁男性内容池。）

从精选内容池中随机抽样几个物品，跳过排序，直接插入最终排序结果。

兴趣探索在短期内对核心指标产生负向影响，但长期来看会产生正向影响。

## 总结：提升多样性

精排：结合兴趣分数和多样性分数做排序；做规则打散。

粗排：只用兴趣分数选出部分物品；结合兴趣分数和多样性分数选出部分物品。

召回：往双塔模型的用户向量添加噪声；对用户行为序列做非均匀随机抽样（对双塔和U2I2I都适用）。

兴趣探索：保留少部分的流量给非个性化推荐。

# 特殊用户人群

这节课的内容是特殊对待特殊的用户人群，比如新用户和低活用户。具体介绍3大类方法：  
1. 构造特殊内容池，用于特殊用户人群的召回。  
2. 使用特殊排序策略，保护特殊用户。  
3. 使用特殊的排序模型，消除模型预估的偏差。

## 为什么要特殊对待特殊人群？

1. 新用户、低活用户的行为很少，个性化推荐不准确。
2. 新用户、低活用户容易流失，要想办法促使他们留存。
3. 特殊用户的行为（比如点击率、交互率）不同于主流用户，基于全体用户行为训练出的模型在特殊用户人群上有偏。

## 涨指标的方法

1. 构造特殊内容池，用于特殊用户人群的召回。  
2. 使用特殊排序策略，保护特殊用户。  
3. 使用特殊的排序模型，消除模型预估的偏差。

## 特殊内容池

### 为什么需要特殊内容池？

- 新用户、低活用户的行为很少，个性化召回不准确。（既然个性化不好，那么就保证内容质量好。）
- 针对特定人群的特点构造特殊内容池，提升用户满意度。（例如，对于喜欢留评论的中年女性，构造促评论内容池，满足这些用户的互动需求。）

### 如何构造特殊内容池？

方法1：根据物品获得的交互次数、交互率选择优质物品。

- 圈定人群：只考虑特定人群，例如18~25岁一二线城市男性。
- 构造内容池：用该人群对物品的交互次数、交互率给物品打分，选出分数最高的物品进入内容池。
- 内容池有弱个性化的效果。
- 内容池定期更新，加入新物品，排除交互率低和失去时效性的老物品。
- 该内容池只对该人群生效。

方法2：做因果推断，判断物品对人群留存率的贡献，根据贡献值选物品。

这种技术还不成熟。

### 特殊内容池的召回

通常使用双塔模型从特殊内容池中做召回。
- 双塔模型是个性化的。
- 对于新用户，双塔模型的个性化做不准。
- 靠高质量内容、弱个性化做弥补。

额外的训练代价？

- 对于正常用户，不论有多少内容池，只训练一个双塔模型。
- 对于新用户，由于历史交互记录很少，需要单独训练模型。

额外的推理代价？

- 内容池定期更新，然后要更新 ANN 索引。
- 线上做召回时，需要做 ANN 检索。
- 特殊内容池都很小（比全量内容池小10~100倍），所以需要的额外算力不大。

## 特殊的排序策略

### 排除低质量物品

对于新用户、低活用户这样的特殊人群，业务上只关注留存，不在乎消费（总曝光量、广告收入、电商收入）。

对于新用户、低活用户，少出广告、甚至不出广告。

新发布的物品不在新用户、低活用户上做探索。

- 物品新发布时，推荐做得不准，会损害用户体验。
- 只在活跃的老用户上做探索，对新物品提权（boost）。
- 不在新用户、低活用户上做探索，避免伤害用户体验。

### 差异化的融分公式

新用户、低活用户的点击和交互行为不同于正常用户。

低活用户的人均点击量很小；没有点击就不会有进一步的交互。

低活用户的融分公式中，提高预估点击率的权重（相较于普通用户）。

保留几个曝光坑位给预估点击率最高的几个物品。

- 例：精排从500个物品中选50个作为推荐结果，其中3个坑位给点击率最高的物品，剩余47个坑位由融分公式决定。
- 甚至可以把点击率最高的物品排在第一，确保用户一定能看到。
## 特殊的排序模型

### 差异化的排序模型

特殊用户人群的行为不同于普通用户。新用户、低活用户的点击率和交互率偏高或偏低。

排序模型被主流用户主导，对特殊用户做不准预估。
- 用全体用户数据训练出的模型，给新用户做的预估有严重偏差。
- 如果一个APP的用户90%是女性，用全体用户数据训练出的模型对男性用户做的预估有偏差。

问题：对于特殊用户，如何让排序模型预估做得准？

方法1：大模型+小模型

- 用全体用户行为训练大模型，大模型的预估p拟合用户行为y。
- ·用特殊用户的行为训练小模型，小模型的预估q拟合大模型的残差y-p。
- 对主流用户只用大模型做预估p。
- 对特殊用户，结合大模型和小模型的预估p+q。

方法2：融合多个experts，类似MMoE。

- 只用一个模型，模型有多个experts，各输出一个向量。
- 对 experts 的输出做加权平均。
- 根据用户特征计算权重。
- 以新用户为例，模型将用户的新老、活跃度等特征作为输入，输出权重，用于对 experts 做加权平均。

方法3：大模型预估之后，用小模型做校准。

- 用大模型预估点击率、交互率。
- 将用户特征丶大模型预估点击率和交互率作为小模型（例如GBDT）的输入。
- 在特殊用户人群的数据上训练小模型，小模型的输出拟合用户真实行为。

## 错误的做法

每个用户人群使用一个排序模型，推荐系统同时维护多个大模型。

- 系统有一个主模型；每个用户人群有自己的一个模型。
- 每天凌晨，用全体用户数据更新主模型。
- 基于训练好的主模型，在某特殊用户人群的数据上再训练 1 epoch，作为该用户人群的模型。

特点：短期可以提升指标；维护代价大，长期有害。

例如：起初，低活男性用户模型比主模型的AUC 高0.2%。主模型迭代几个版本后，AUC累计提升0.5%°·特殊人群模型太多，长期没有人维护和更新。如果把低活男性用户模型下线，换成主模型，在低活男性用户 上的 AUC 反倒提升 0.3% ！

赢两次不可取！因为只是浪费了算力，对模型没有改变。

## 总结：特殊对待特殊用户人群

- 召回：针对特殊用户人群，构造特殊的内容池，增加相应的召回通道。
- 排序策略：排除低质量物品，保护新用户和低活用户；特殊用户人群使用特殊的融分公式。
- 排序模型：结合大模型和小模型，小模型拟合大模型的残差；只用一个模型，模型有多个experts；大模型预估之后，用小模型做校准。

# 交互行为（关注、转发、评论）

这节课的内容是利用关注、转发、评论这三种交互行为给推荐系统涨指标。

## 用户的交互行为

交互行为：点赞、收藏、转发、关注、评论·····

推荐系统如何利用交互行为？

最简单的方法：将模型预估的交互率用于排序。

- 模型将交互行为当做预估的目标。
- 将预估的点击率、交互率做融合，作为排序的依据。

交互行为有没有其他用途？

## 关注

### 关注量对留存的价值

一位用户关注的作者越多，则平台对他的吸引力越强。

用户留存率（r）与他关注的作者数量（f）正相关。

如果某用户的f较小，则推荐系统要促使该用户关注更多作者。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250301101156.png)

### 如何利用关注关系提升用户留存？

方法1：用排序策略提升关注量。

- 对于用户u，模型预估候选物品i的关注率为$p_i$。
- 设用户u已经关注了f个作者。
- 我们定义单调递减函数$w(f)$，用户已经关注的作者越多，则 $w(f)$ 越小。
- 在排序融分公式中添加$w(f) \cdot p_i$用于促关注。（如果 f 小且$p_i$大则$w(f) \cdot p_i$给物品$i$带来很大加分。）

方法2：构造促关注内容池和召回通道。

- 这个内容池中物品的关注率高，可以促关注。
- 如果用户关注的作者数f较小，则对该用户使用该内容池。
- 召回配额可以固定，也可以与f负相关。

### 粉丝数对促发布的价值

UGC平台将作者发布量、发布率作为核心指标，希望作者多发布。

作者发布的物品被平台推送给用户，会产生点赞、评论、关注等交互。

交互（尤其是关注、评论）可以提升作者发布积极性。

作者的粉丝数越少，则每增加一个粉丝对发布积极性的提升越大。

用排序策略帮助低粉新作者涨粉。

某作者a的粉丝数（被关注数）为$f_a$。作者a发布的物品i可能被推荐给用户u，模型预估关注率为$p_{ui}$。我们定义单调递减函数$w(f_a)$作为权重；作者a的粉丝越多，则$w(f_a)$越小。
在排序融分公式中添加$w(f_a) \cdot p_{ui}$帮助低粉作者涨粉。

### 隐式关注关系

召回通道 U2A2I ：user → author →item。

显式关注关系：用户u关注了作者a，将a发布的物品推荐给u。（点击率、交互率指标通常高于其他召回通道。)

隐式关注关系：用户u喜欢看作者a发布的物品，但是u 没有关注a。

隐式关注的作者数量远大于显式关注。挖掘隐式关注关系，构造U2A2I召回通道，可以提升推荐系统核心指标。

## 转发

### 促转发（分享回流）

A平台用户将物品转发到B平台，可以为A吸引站外流量。

推荐系统做促转发（也叫分享回流）可以提升DAU和消费指标。

简单提升转发次数是否有效呢？

- 模型预估转发率为$p$，融分公式中有一项$w \cdot p$，让转发率大的物品更容易获得曝光机会。
- 增大权重$w$可以促转发，吸引站外流量，但是会对点击率和其他交互率产生负面影响。

### KOL建模

目标：在不损害点击和其他交互的前提下，尽量多吸引站外流量。

什么样的用户的转发可以吸引大量站外流量？其他平台的Key Opinion Leader (KOL)！

- 答案：其他平台的 Key Opinion Leader（KOL）。
- 用户u是我们站内的KOL，但他不是其他平台的KOL，他的转发价值大吗？不大
- 用户在我们站内没有粉丝，但他是其他平台的KOL，他的转发价值大吗？大

如何判断本平台的用户是不是其他平台的KOL？该用户历史上的转发能带来多少站外流量。

### 促转发的策略

目标：在不损害点击和其他交互的前提下，尽量多吸引站外流量。

识别出的站外KOL之后，该如何用于排序和召回？

方法1：排序融分公式中添加额外的一项$k_u \cdot p_{ui}$。

- $k_u$：如果用户u是站外KOL，则$k_u$大。
- $p_{ui}$：为用户u推荐物品i，模型预估的转发率。
- 如果u是站外KOL，则多给他曝光他可能转发的物品。

方法2：构造促转发内容池和召回通道，对站外KOL生效。

## 评论

### 评论促发布

UGC平台将作者发布量、发布率作为核心指标，希望作者多发布。

关注、评论等交互可以提升作者发布积极性。

如果新发布物品尚未获得很多评论，则给预估评论率提权，让物品尽快获得评论。

排序融分公式中添加额外一项$w_i \cdot p_i$。

- $w_i$：权重，与物品$i$已有的评论数量负相关。
- $p_i$：为用户推荐物品$i$，模型预估的评论率。

### 评论的其他价值

有的用户喜欢留评论，喜欢跟作者、评论区用户互动。
- 给这样的用户添加促评论的内容池，让他们更多机会参与讨论。
- 有利于提升这些用户的留存。

有的用户常留高质量评论（评论的点赞量高）。

- 高质量评论对作者、其他用户的留存有贡献。（作者、其他用户觉得这样的评论有趣或有帮助。）
- 用排序和召回策略鼓励这些用户多留评论。

## 总结：利用交互行为

关注：留存价值（让新用户关注更多作者，提升新用户留存）；发布价值（帮助新作者获得更多粉丝，提升作者发布积极性）；利用隐式关注关系做召回。

转发：判断哪些用户是站外的KOL，利用他们转发的价值，吸引站外的流量。

评论：发布价值（促使新物品获得评论，提升作者发布积极性）；留存价值（给喜欢讨论的用户创造更多留评机会）；鼓励高质量评论的用户多留评论。

