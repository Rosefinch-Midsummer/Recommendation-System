# 推荐系统基础

<!-- toc -->

## 基本概念

### 转化流程

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214101705.png)

### 消费指标

- 点击率=点击次数／曝光次数
- 点赞率=点赞次数／点击次数
- 收藏率=收藏次数／点击次数
- 转发率=转发次数／点击次数
- 阅读完成率=滑动到底次数／点击次数×f(笔记长度)

f(笔记长度)为归一化函数。

### 北极星指标（最关键指标）

- 用户规模：日活用户数（DAU）、月活用户数（MAU）
- 消费：人均使用推荐的时长、人均阅读笔记的数量。
- 发布：发布渗透率、人均发布量。

### 实验流程

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214101633.png)

## 推荐系统链路

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214101902.png)

召回：用多条通道，取回几千篇笔记。

粗排：用小规模神经网络，给几千篇笔记打分，选出分数最高的几百篇。

精排：用大规模神经网络，给几百篇笔记打分。

重排：做多样性抽样丶规则打散丶插入广告和运营笔记。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214102645.png)

召回通道： 协同过滤、双塔模型、关注的作者等等。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214102738.png)

重排流程：

- 做多样性抽样（比如MMR、DPP）从几百篇中选出几十篇。
- 用规则打散相似笔记。
- 插入广告、运营推广内容，根据生态要求调整排序。

## 推荐系统的AB测试

召回团队实现了一种GNN召回通道，离线实验结果正向。

下一步是做线上的小流量A/B测试，考察新的召回通道对线上指标的影响。

模型中有一些参数，比如 GNN 的深度取值∈{1,2,3}， 需要用A/B测试选取最优参数。

### 随机分桶

分 b=10 个桶，每个桶中有 10% 的用户。

首先用哈希函数把用户ID映射成某个区间内的整数，然后把这些整数均匀随机分成b个桶。

全部n位用户，分成b个桶，每个桶中有$\frac{b}{n}$位用户

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214111303.png)

### 分层实验

目标：解决流量不够用的问题

信息流产品的公司有很多部门和团队，大家都需要做A/B 测试。

- 推荐系统（召回、粗排、精排、重排)
- 用户界面
- 广告

如果把用户随机分成10组，1组做对照，9组做实验，那么只能同时做9组实验。

分层实验：召回、粗排、精排、重排、用户界面、广告····(例如 GNN 召回通道属于召回层。)

- 同层互斥：GNN实验占了召回层的4个桶，其他召回实验只能用剩余的6个桶。
- 不同层正交：每一层独立随机对用户做分桶。每一层都可以独立用100%的用户做实验。

召回层把用户分成10个桶：$U_1,U_2,,U_{10}$ 

精排层把用户分成10个桶：$V_1,V2,,V_{10}$

设系统共有n个用户，那么$|U_i|=|V_j|=n/10$

召回桶$U_i$ 和召回桶$U_j$ 交集为$U_i \cap U_j = \phi$ 

召回桶$U_i$ 和精排桶$V_j$ 交集的大小为$U_i \cap V_j = n/100$ 

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214112200.png)

互斥VS正交：

- 如果所有实验都正交，则可以同时做无数组实验。
- 同类的策略（例如精排模型的两种结构）天然互斥，对于一个用户，只能用其中一种。
- 同类的策略（例如添加两条召回通道）效果会相互增强（1+1>2）或相互抵消（1+1<2）。互斥可以避免同类策略相互干扰。
- 不同类型的策略 (例如添加召回通道、优化粗排模型) 通常不会相互干扰（1+1=2），可以作为正交的两层。

### Holdout 机制

每个实验（召回、粗排丶精排丶重排）独立汇报对业务指标的提升。

公司考察一个部门（比如推荐系统）在一段时间内对业务指标总体的提升。

取 10% 的用户作为holdout 桶（对照组），推荐系统使用剩余 90%的用户做实验，两者互斥。

10% holdout 桶 vs 90% 实验桶的 diff (需要归一化) 为整个部门的业务指标收益。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214105933.png)

每个考核周期结束之后，清除holdout 桶，让推全实验从90%用户扩大到100%用户。

重新随机划分用户，得到holdout 桶和实验桶’开始下一轮考核周期。

新的 holdout 桶与实验桶各种业务指标的 diff接近0。

随着召回、粗排、精排、重排实验上线和推全，diff 会逐渐扩大。

### 实验推全&反转实验

为什么要进行反转实验？

有的指标（点击、交互）立刻收到新策略影响，有的指标（留存）有滞后性，需要长期观测。

实验观测到显著收益后尽快推全新策略。目的是腾出桶供其他实验使用，或需要基于新策略做后续的开发。

用反转实验解决上述矛盾，既可以尽快推全，也可以长期观测实验指标。

在推全的新层中开一个旧策略的桶，长期观测实验指标。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250214112739.png)

### 总结

分层实验：同层互斥（不允许两个实验同时影响一位用户）、不同层正交（实验有重叠的用户）。

Holdout：保留10% 的用户，完全不受实验影响，可以考察整个部门对业务指标的贡献。

实验推全：新建一个推全层，与其他层正交。

反转实验：在新的推全层上’保留一个小的反转桶，使用旧策略。长期观测新旧策略的diff。
## 附录A/B测试

A/B 测试是一种用于比较两种或多种版本的产品、网页、广告等，以确定哪一种效果更好的实验方法。它通常用于优化用户体验、提高转化率或评估新功能的影响。以下是对 A/B 测试的详细介绍：

### 1. **基本概念**
- **A/B 分组**：在 A/B 测试中，用户被随机分为两个或多个组，例如“版本A”和“版本B”。每个组看到的是不同版本的内容。
- **关键指标**：测试的目标可能是提高点击率、转化率、用户留存率等。通过比较这些指标，分析哪一版本表现更好。

### 2. **实施步骤**
2. **明确目标**：首先清楚你想要改善的具体指标，例如销售额、注册用户数量等。
3. **选择变量**：决定要测试的内容，比如按钮颜色、文案、图片等。
4. **创建版本**：根据选择的变量，设计不同的版本。
5. **流量分配**：将用户随机分配到不同的版本中，确保流量来源一致。
6. **收集数据**：在测试期间，持续收集用户行为数据。
7. **分析结果**：使用统计方法分析数据，评估哪个版本的表现更优。
8. **做出决策**：基于测试结果，决定是否采纳新的版本。

### 3. **优点和缺点**

优点：
- **数据驱动**：帮助做出基于实际数据的决策，而不是凭直觉。
- **简单明了**：易于理解和实施，不需要复杂的分析。
- **实时反馈**：可以在实施中快速获取反馈，及时调整策略。

缺点：
- **样本大小**：如果样本量不足，结果可能不具备统计意义。
- **时间消耗**：某些测试可能需要较长时间才能收集到足够的数据。
- **外部影响**：外部因素（如市场波动）可能影响测试结果的准确性。

### 4. **应用场景**
A/B 测试广泛应用于电子商务网站、移动应用、营销广告、用户界面设计等多个领域。通过这些测试，企业可以依据用户行为做出更优的决策，从而提升整体业绩。