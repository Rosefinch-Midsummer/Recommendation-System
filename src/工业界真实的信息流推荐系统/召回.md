# 召回

<!-- toc -->

# Item CF

这节课介绍基于物品的协同过滤（Item Based Collaborative Filtering，缩写 ItemCF）。  
  
ItemCF 的原理：如果用户喜欢物品1，而且物品1与物品2相似，那么用户很可能喜欢物品2。  
  
这节课的三个要点：  
1. 如何计算两个物品之间的相似度。  
2. 如何预估用户对候选物品的兴趣。  
3. 如何利用索引在线上快速做召回。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309131821.png)
## Item CF的原理

用户喜欢物品$i_1$，那么用户喜欢与物品$i_1$相似的物品$i_2$。

如果喜欢$i_1, i_2$的用户有很大的重叠，那么$i_1$与$i_2$相似。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309120951.png)
### 物品相似度计算

两个物品的受众重合度越高，两个物品越相似。

例如：喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很高。可以认为《射雕英雄传》和《神雕侠侣》相似。

喜欢物品$i_1$的用户记作集合$w_1$。

喜欢物品$i_2$的用户记作集合$w_2$

定义交集 $v = w_1 \cap  w_2$  

物品相似度计算公式：$sim(i_1, i_2) = \frac{|w_1 \cap w_2|}{\sqrt {|w_1 \cdot w_2|}}$，注意该公式没有考虑喜欢的程度$like(user, item)$

下面的公式考虑了喜欢的程度

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309131710.png)
## 召回流程
### 事先做离线计算

建立“用户→物品”的索引
- 记录每个用户最近点击、交互过的物品ID。
- 给定任意用户ID，可以找到他近期感兴趣的物品列表。

建立“物品→物品”的索引
- 计算物品之间两两相似度。
- 对于每个物品，索引它最相似的k个物品
- 给定任意物品ID，可以快速找到它最相似的k个物品。
### 线上做召回

索引的意义在于避免枚举所有的物品。

1. 记录用户最近感兴趣的$n=200$个物品。 
2. 取回每个物品最相似的$k=10$个物品。
3. 给取回的$nk=2000$个物品打分（用户对物品的兴趣） 
4. 返回分数最高的100个物品作为ItemCF通道的输出。

用索引，离线计算量大，线上计算量小。
### Item CF召回通道

维护两个索引：
- 用户→物品列表：用户最近交互过的n个物品。
- 物品→物品列表：相似度最高的k个物品。

线上做召回：
- 利用两个索引，每次取回$n \cdot k$个物品。
- 预估用户对每个物品的兴趣分数：$\sum_j like(user,item_j) × sim(item_j,item)$
- 返回分数最高的100个物品，作为召回结果。

## ItemCF实现

实现基于Item-CF（物品协同过滤）推荐算法的过程与User-CF算法类似，但焦点在物品之间的相似度计算上。以下是详细的步骤和代码示例，以帮助你理解如何实现Item-CF推荐算法。

### 1. 数据加载和用户-物品矩阵

如果你已经加载了MovieLens数据集，并创建了用户-物品矩阵，可以跳过这个步骤。不过，为了完整性，以下代码会重新载入数据并构建用户-物品矩阵：

```python
import pandas as pd

# 加载数据集
data = pd.read_csv('u.data', delimiter='\t', names=['user_id', 'item_id', 'rating', 'timestamp'])

# 创建用户-物品矩阵
user_item_matrix = data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)
user_item_matrix = user_item_matrix.values
```

### 2. 计算物品相似度

这一步是计算物品之间的相似度，通常使用余弦相似度或皮尔逊相关系数。下面示范如何使用余弦相似度：

```python
from sklearn.metrics.pairwise import cosine_similarity

# 计算物品相似度
item_similarity = cosine_similarity(user_item_matrix.T)
item_similarity_df = pd.DataFrame(item_similarity)
print(item_similarity_df.head())
```

### 3. 生成推荐列表

基于计算出的物品相似度，我们可以为每个用户生成推荐列表。对于Item-CF，我们会根据用户已评分的物品找到相似物品，然后进行推荐。

```python
def get_item_recommendations(user_id, user_item_matrix, item_similarity, n_recommendations=5):
    # 获取指定用户的评分
    user_index = user_id - 1  # 假设用户ID是从1开始
    user_ratings = user_item_matrix[user_index]
    
    # 计算与用户已评分物品相似的物品
    similar_score = item_similarity.dot(user_ratings)
    
    # 过滤已评分的物品
    similar_score[user_ratings > 0] = 0
    
    # 获取推荐物品
    recommended_items_indices = similar_score.argsort()[::-1][:n_recommendations]
    
    return recommended_items_indices + 1  # 返回物品ID，从1开始

# 示例：生成用户1的推荐列表
recommendations = get_item_recommendations(1, user_item_matrix, item_similarity)
print("推荐列表:", recommendations)
```

### 4. 评估推荐效果

与User-CF类似，我们可以计算**precision**、**recall**、**F1 score** 和 **多样性**，以评估推荐效果。

```python
def calculate_precision_recall(recommendations, true_items, k=5):
    true_positive = len(set(recommendations[:k]) & set(true_items))
    precision = true_positive / k
    recall = true_positive / len(true_items) if len(true_items) > 0 else 0
    F1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    return precision, recall, F1_score

# 用于测试的真实购买和推荐 (假设)
true_items = [50, 55, 25]  # 用户真实评分的物品ID
k = 5

precision, recall, F1_score = calculate_precision_recall(recommendations, true_items, k)
print(f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {F1_score:.2f}')
```

### 5. 计算多样性

和在User-CF中一样，多样性可以通过计算推荐物品之间的相似度来测量。

```python
def calculate_diversity(recommendations, item_similarity):
    # 过滤推荐物品的相似度
    if len(recommendations) <= 1:
        return 0
    sim_sum = sum(item_similarity[i-1][j-1] for i in recommendations for j in recommendations if i != j)
    diversity = 1 - (sim_sum / (len(recommendations) * (len(recommendations) - 1)))  # 多样性分值
    return diversity

diversity = calculate_diversity(recommendations, item_similarity)
print(f'Diversity: {diversity:.2f}')
```

### 总结

通过以上步骤，你可以实现一个基于Item-CF的推荐系统。它的核心在于计算物品相似度，并根据用户的评分生成个性化的推荐列表。你可以根据不同的计算方法和参数来优化推荐效果，提高模型的性能。


# Swing 模型

这节课介绍 Swing 模型，它跟 ItemCF 非常类似，唯一的区别在于计算物品相似度的方式不同。

## 原理

和Item CF区别是定义物品相似度的方法不同。

Swing 模型给用户设置权重来解决小圈子问题。

用户$u_1$ 喜欢的物品记作集合$J_1$

用户$u_2$ 喜欢的物品记作集合$J_2$

定义两个用户的重合度：$overlap(u_1,u_2) = |J_1 \cap J_2 |$ 

用户 $u_1$ 和$u_2$ 的重合度高，则他们可能来自一个小圈子；要降低他们的权重。

喜欢物品$i_1$ 的用户记作集合$W_1$

喜欢物品 $i_2$ 的用户记作集合$W_2$

定义交集 $V = W_1 \cap  W_2$  

两个物品的相似度：

$$
\text{sim}(i_1, i_2) = \sum_{u_1 \in \mathcal{V}} \sum_{u_2 \in \mathcal{V}} \frac{1}{\alpha + \text{overlap}(u_1, u_2)}
$$


## 总结

Swing与Item CF唯一的区别在于物品相似度的计算方式。

Item CF：两个物品重合的用户比例高，则判定两个物品相似。

Swing：额外考虑重合的用户是否来自一个小圈子。
- 同时喜欢两个物品的用户记作集合V。
- 对于$V$中的用户$u_1$和$u_2$重合度记作$overlap(u_1,u_2)$。
- 两个用户重合度大，则可能来自一个小圈子，权重降低。

# User CF

这节课介绍基于用户的召回（User Based Collaborative Filtering，缩写 UserCF）。  
  
UserCF 的原理：如果用户1跟用户2相似，而且用户2喜欢某物品，那么用户1很可能喜欢该物品。  
  
这节课的三个要点：  
1. 如何计算两个用户之间的相似度。  
2. 如何预估用户对候选物品的兴趣。  
3. 如何利用索引在线上快速做召回。

UserCF 的基本思想：

- 如果用户$user_1$跟用户$user_2$相似，而且$user_2$喜欢某物品，那么用户$user_1$也很可能喜欢该物品。
- 预估用户$user_1$对候选物品$item$的兴趣：$\sum_{j}sim(user, user_j) \times like(user_j,item)$
- 计算两个用户的相似度：把每个用户表示为一个稀疏向量，向量每个元素对应一个物品。相似度sim 就是两个向量夹角的余弦。
## UserCF的原理

有很多跟我兴趣非常相似的网友，其中某个网友对某笔记点赞、转发，我没看过这篇笔记=>给我推荐这篇笔记

推荐系统如何找到跟我兴趣非常相似的网友呢?

方法一：点击、点赞、收藏、转发的笔记有很大的重合。

方法二：关注的作者有很大的重合。

## 计算用户相似度

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250215111317.png)
### 计算相似度公式

用户$u_1$ 喜欢的物品记作集合$J_1$

用户$u_2$ 喜欢的物品记作集合$J_2$

定义交集 $I = J_1 \cap J_2$ 

两个用户的相似度：

$sim(u_1, u_2) = \frac{|I|}{\sqrt {|J_1 \cdot J_2|}}$
### 降低热门物品权重

用户$u_1$ 喜欢的物品记作集合$J_1$

用户$u_2$ 喜欢的物品记作集合$J_2$

定义交集 $I = J_1 \cap J_2$ 

两个用户的相似度：

$$sim(u_1,u_2)=\frac{\sum_{l\in I}\frac{1}{\log(1+n_l)}}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}}$$

其中$n_l$指喜欢物品$l$的用户数量，反映物品的热门程度

## 召回流程

### 事先做离线计算

建立“用户→物品”的索引

- 记录每个用户最近点击、交互过的物品ID。
- 给定任意用户ID，可以找到他近期感兴趣的物品列表。

建立“用户→用户”的索引
- 对于每个用户，索引他最相似的k个用户。
- 给定任意用户ID，可以快速找到他最相似的k个用户。

### 线上做召回

1. 给定用户ID，通过“用户→用户”索引，找到top-k相似用户。
2. 对于每个top-k相似用户，通过“用户→物品”索引’找到用户近期感兴趣的物品列表（last-n）。
3. 对于召回的nk个相似物品，用公式预估用户对每个物品的兴趣分数。
4. 返回分数最高的100个物品，作为召回结果。

### UserCF召回通道

维护两个索引：
- 用户→物品列表：用户近期交互过的n个物品。
- 用户→用户列表：相似度最高的k个用户。

线上做召回：
- 利用两个索引，每次取回nk个物品。
- 预估用户user对每个物品item 的兴趣分数：$\sum_{j}sim(user, user_j) \times like(user_j,item)$
- 返回分数最高的100个物品，作为召回结果。
## UserCF实现

实现基于User-CF（用户协同过滤）推荐算法的整个过程可以分为几个关键步骤，包括数据加载、用户相似度计算、生成推荐列表以及评价推荐效果。下面是一个详细的说明和代码示例。

### 1. 数据加载

我们首先需要加载MovieLens数据集。假设我们使用的是MovieLens 100k数据集，它通常包含两列，用户ID和电影ID。

```python
import pandas as pd

# 加载数据集
data = pd.read_csv('u.data', delimiter='\t', names=['user_id', 'item_id', 'rating', 'timestamp'])
print(data.head())
```

### 2. 创建用户-物品矩阵

接下来，我们需要构建一个用户-物品矩阵，其中行表示用户，列表示物品，值表示评分。

```python
# 创建用户-物品矩阵
user_item_matrix = data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)
user_item_matrix = user_item_matrix.values
```

### 3. 计算用户相似度

在这一部分，我们将计算用户之间的相似度。最常用的方法是余弦相似度。

```python
from sklearn.metrics.pairwise import cosine_similarity

# 计算用户相似度
user_similarity = cosine_similarity(user_item_matrix)
user_similarity_df = pd.DataFrame(user_similarity)
print(user_similarity_df.head())
```

### 4. 生成推荐列表

基于用户相似度，我们可以为每个用户生成推荐列表。我们将为每个用户找到与其相似度最高的用户，根据这些用户的评分来生成推荐。

```python
def get_recommendations(user_id, user_item_matrix, user_similarity, n_recommendations=5):
    # 获取指定用户的评分
    user_index = user_id - 1  # 假设用户ID是从1开始
    similar_users = user_similarity[user_index]
    
    # 找到与当前用户最相似的用户
    similar_users_indices = similar_users.argsort()[::-1][:10]  # 获取前10个相似用户
    
    # 计算推荐评分
    weighted_ratings = user_item_matrix[similar_users_indices].T.dot(similar_users[similar_users_indices])
    
    # 过滤已评分的物品
    user_ratings = user_item_matrix[user_index]
    weighted_ratings[user_ratings > 0] = 0  # 不推荐已评分的物品
    
    # 获取推荐物品
    recommended_items_indices = weighted_ratings.argsort()[::-1][:n_recommendations]
    
    return recommended_items_indices + 1  # 返回物品ID，从1开始

# 示例：生成用户1的推荐列表
recommendations = get_recommendations(1, user_item_matrix, user_similarity)
print("推荐列表:", recommendations)
```

### 5. 评估推荐效果

推荐效果的评估通常会计算 **precision**、**recall**、**F1 score** 和 **多样性**。这里我们手动计算这些指标。

```python
def calculate_precision_recall(recommendations, true_items, k=5):
    true_positive = len(set(recommendations[:k]) & set(true_items))
    precision = true_positive / k
    recall = true_positive / len(true_items) if len(true_items) > 0 else 0
    F1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    return precision, recall, F1_score

# 用于测试的真实购买和推荐 (假设)
true_items = [50, 55, 25]  # 用户真实评分的物品ID
k = 5

precision, recall, F1_score = calculate_precision_recall(recommendations, true_items, k)
print(f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {F1_score:.2f}')
```

### 6. 计算多样性

多样性可以通过计算推荐物品之间的相似度来测量。

```python
def calculate_diversity(recommendations, user_item_matrix):
    # 过滤推荐物品的相似度
    item_similarity = cosine_similarity(user_item_matrix.T)
    
    # 计算推荐物品之间的相似度平均值
    if len(recommendations) <= 1:
        return 0
    sim_sum = sum(item_similarity[i-1][j-1] for i in recommendations for j in recommendations if i != j)
    diversity = 1 - (sim_sum / (len(recommendations) * (len(recommendations) - 1)))  # 多样性分值
    return diversity

diversity = calculate_diversity(recommendations, user_item_matrix)
print(f'Diversity: {diversity:.2f}')
```

### 总结

这个代码示例构建了一个完整的User-CF推荐系统，涵盖了用户相似度计算、推荐生成以及评估指标的计算。你可以通过调整参数或使用不同的相似度计算方法来优化推荐效果。


# 离散特征处理

这节课的内容是离散特征的处理，包括 one-hot encoding (独热编码) 和 embedding (嵌入)。这节课是为后面几节课的向量召回做准备。

## 流程

1. 建立字典：把类别映射成序号
	- 中国→1
	- 美国→2
	- 印度→3
2. 向量化：把序号映射成向量。
	- One-hot编码：把序号映射成高维稀疏向量
	- Embedding：把序号映射成低维稠密向量

## One-hot编码

例1：性别特征

性别：男、女两种类别。

字典：男→1，女→2。

One-hot编码：用 2 维向量表示性别

- 未知→0 →[0,0]
- 男→1→[1,0]
- 女→ 2→ [0,1]

例2：国籍特征

国籍：中国、美国、印度等200种类别。

字典：中国→1，美国→2，印度→3，

One-hot编码：用 200 维稀疏向量表示国籍

- 未知 → 0 → [0,0,0,0,...,0]
- 中国→1→[1,0,0,0,...,0]
- 美国 → 2 → [0,1,0,0,...,0]
- 印度→3→[0,0,1,0,...,0]

One-Hot编码的局限：类别数量太大时，通常不用one-hot 编码。

例1：自然语言处理中，对单词做编码。英文有几万个常见单词。那么one-hot向量的维度是几万

例2：推荐系统中，对物品ID做编码，小红书有几亿篇笔记，那么one-hot向量的维度是几亿。

## Embedding（嵌入）

例 1：国籍的Embedding

参数数量：向量维度×类别数量

设embedding得到的向量都是4维的。一共有200个国籍。参数数量=4×200=800。

编程实现：TensorFlow、PyTorch 提供 embedding 层。

参数以矩阵的形式保存，矩阵大小是向量维度×类别数量。

输入是序号，比如“美国”的序号是2。

输出是向量，比如“美国”对应参数矩阵的第2列。

例2：物品ID的Embedding

数据库里一共有10,000部电影。任务是给用户推荐电影。设embedding 向量的维度是 16。Embedding 层有多少参数？

参数数量=向量维度× 类别数量=160,000
## One-hot和Embedding的关系

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250215113509.png)
## 总结

离散特征处理：one-hot 编码、embedding

类别数量很大时，用embedding，例如：
- Word embedding
- 用户 ID embedding
- 物品 ID embedding


# 向量召回

这节课介绍矩阵补充（matrix completion），它是一种向量召回通道。矩阵补充的本质是对用户 ID 和物品 ID 做 embedding，并用两个 embedding 向量的內积预估用户对物品的兴趣。值得注意的是，矩阵补充存在诸多缺点，在实践中效果远不及双塔模型。  
  
做向量召回需要做最近邻查找（nearest neighbor search）。这节课的最后介绍加速最近邻查找的近似算法以及工业界的实践。
## 矩阵补充（Matrix Completion）

### 矩阵补充架构图

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309115231.png)

### 基本想法

用户embedding参数矩阵记作A。第u号用户对应矩阵第u列，记作向量$a_u$。

物品embedding参数矩阵记作B。第i号物品对应矩阵第i列，记作向量$b_i$。

内积$<a_u,b_i>$是第u号用户对第i号物品兴趣的预估值。

训练模型的目的是学习矩阵A和B，使得预估值拟合真实观测的兴趣分数。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309115605.png)

### 矩阵补充缺点

矩阵补充在实践中效果不好

缺点1：仅用ID embedding，没利用物品、用户属性

- 物品属性：类目、关键词、地理位置、作者信息
- 用户属性：性别、年龄、地理定位、感兴趣的类目

双塔模型可以看做矩阵补充的升级版。

缺点2：负样本的选取方式不对。

- 样本：用户—物品的二元组，记作（u,i）
- 正样本：曝光之后，有点击、交互。（正确的做法）
- 负样本：曝光之后，没有点击、交互。（错误的做法）

缺点3：做训练的方法不好。

- 内积$<a_u,b_i>$不如余弦相似度
- 用平方损失（回归），不如用交叉熵损失（分类）

## 线上服务

### 模型存储

1. 训练得到矩阵A和B
	- A的每一列对应一个用户
	- B的每一列对应一个物品。
2. 把矩阵 A 的列存储到 key-value 表
	- key是用户ID，value是A的一列
	- 给定用户ID，返回一个向量（用户的embedding）

3. 矩阵B的存储和索引比较复杂。

### 线上服务

1. 把用户ID作为key查询key-value 表，得到该用户的向量，记作a。
2. 最近邻查找：查找用户最有可能感兴趣的k个物品，作为召回结果。
	- 第$i$号物品的 embedding 向量记作$b_i$
	- 内积$<a,b_i>$是用户对第$i$号物品兴趣的预估。
	- 返回内积最大的$k$个物品。

如果枚举所有物品，时间复杂度正比于物品数量。

### 近似最近邻查找（Approximate Nearest Neighbor Search）

支持最近邻查找的系统：Milvus、Faiss、HnswLib等等

衡量最近邻的标准：
- 欧式距离最小（L2距离）
- 向量内积最大（内积相似度）
- 向量夹角余弦最大（cosine相似度）

### 总结

矩阵补充：

- 把物品ID、用户ID做embedding，映射成向量。
- 两个向量的内积$<a_u,b_i>$作为用户$u$对物品$i$兴趣的预估。
- 让$<a_u,b_i>$拟合真实观测的兴趣分数，学习模型的 embedding 层参数。
- 矩阵补充模型有很多缺点，效果不好。

线上召回：

- 把用户向量a作为 query，查找使得$<a,b_i>$最大化的物品$i$。
- 暴力枚举速度太慢。实践中用近似最近邻查找。
- Milvus、Faiss、HnswLib等向量数据库支持近似最近邻查找。

# 双塔模型

用户塔、物品塔各输出一个向量。

两个向量的余弦相似度作为兴趣的预估值。

三种训练方式：
- Pointwise：每次用一个用户、一个物品（可正可负）
- Pairwise：每次用一个用户、一个正样本、一个负样本
- Listwise：每次用一个用户、一个正样本、多个负样本。

正样本：曝光而且有点击

简单负样本：
- 全体物品
- batch内负样本

困难负样本：被召回，但是被排序淘汰。

错误：曝光、但是未点击的物品做召回的负样本。

双塔模型
- 用户塔、物品塔各输出一个向量；两个向量的余弦相似度作为兴趣的预估值。
- 三种训练的方式：pointwise、pairwise、listwise
- 正样本：用户点击过的物品。
- 负样本：全体物品（简单）、被排序淘汰的物品（困难）。

召回
- 做完训练，把物品向量存储到向量数据库，供线上最近邻查找。
- 线上召回时，给定用户ID、用户画像，调用用户塔现算用户向量a。
- 把a作为query，查询向量数据库，找到余弦相似度最高的k个物品向量，返回k个物品ID。

更新模型
- 全量更新：今天凌晨，用昨天的数据训练整个神经网络；做1 epoch 的随机梯度下降。
- 增量更新：用实时数据训练神经网络，只更新ID Embedding，锁住全连接层。

实际的系统：
- 全量更新&增量更新相结合。
- 每隔几十分钟，发布最新的用户ID Embedding，供用户塔在线上计算用户向量。

双塔模型学不好低曝光物品的向量表征。（这是数据的问题）

自监督学习：
- 对物品做随机特征变换。
- 特征向量$b_i'$和$b_i''$相似度高（相同物品）
- 特征向量$b_i'$和$b_j''$相似度低（不同物品）

实验效果：低曝光物品、新物品的推荐变得更准。

对点击做随机抽样，得到n对用户—物品二元组，作为一个batch。

做梯度下降，使得损失减小：

总的损失 = 双塔模型的损失 + 自监督学习的损失即$cost = \frac{1}{n} \sum_{i=1}^{n} L_{\text{main}}[i] + \alpha \cdot \frac{1}{m} \sum_{j=1}^{m} L_{\text{self}}[j]$

## 模型结构、训练方法

双塔模型（two-tower）也叫 DSSM，是推荐系统中最重要的召回通道，没有之一。这节课的内容是双塔模型的结构、训练方式。  
  
双塔模型有两个塔：用户塔、物品塔。两个塔各输出一个向量，作为用户、物品的表征。两个向量的內积或余弦相似度作为对兴趣的预估。  
  
有三种训练双塔模型的方式：pointwise、pairwise、listwise。

### 模型结构

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309103143.png)

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309103123.png)

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250216093614.png)

### 双塔模型的训练

- Pointwise：独立看待每个正样本、负样本；做简单的二元分类
- Pairwise：每次取一个正样本、一个负样本[1]
- Listwise：每次取一个正样本、多个负样本[2]

#### 正负样本的选择

- 正样本：用户点击的物品
- 负样本`[1,2]`:
	- 没有被召回的？
	- 召回但是被粗排、精排淘汰的？
	- 曝光但是未点击的？

#### Pointwise训练
- 把召回看做二元分类任务。
- 对于正样本’鼓励cos(a,b)接近+1
- 对于负样本鼓励cos(a,b)接近－1
- 控制正负样本数量为 1:2 或者 1:3。

#### Pairwise训练

基本想法：鼓励$cos(a, b^+)$ 大于 $cos(a,b^-)$

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309103557.png)

常用损失函数：
- Triplet hinge loss
- Triplet logistic loss

$$\textbf{Triplet hinge loss:} L(a, b^+, b^-) = \max\left( 0, \cos(a, b^-) + m - \cos(a, b^+) \right). $$

$$\textbf{Triplet logistic loss:} \\
L(a, b^+, b^-) = \log\left(1 + \exp\left(\cos(a, b^-) - \cos(a, b^+)\right)\right).$$

#### Listwise训练

一条数据包含：
- 一个用户，特征向量记作 a。
- 一个正样本，特征向量记作b+。
- 多个负样本，特征向量记作$b_1^-,...,b_n^-$。 

鼓励 cos(a,b+）尽量大

鼓励 $cos(a,b_1^{-})$,$cos(a,b_n^{-})$尽量小

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250216094900.png)

#### 不适用于召回的模型

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250216095822.png)

这里是前期融合，常用于粗排或精排，而双塔模型是后期融合。

## 正负样本

这节课讲解双塔模型（two-tower，也叫 DSSM）正负样本的选取。正样本是有点击的物品。负样本是被召回、排序淘汰的物品，分为简单负样本和困难负样本。

### 正样本

正样本：曝光而且有点击的用户一物品二元组。（用户对物品感兴趣）。

问题：少部分物品占据大部分点击，导致正样本大多是热门物品。

解决方案：过采样冷门物品，或降采样热门物品。

- 过采样（up-sampling）：一个样本出现多次。
- 降采样（down-sampling）：一些样本被抛弃。

### 简单负样本：全体物品

- 未被召回的物品，大概率是用户不感兴趣的。
- 未被召回的物品 ≈全体物品
- 从全体物品中做抽样；作为负样本。
- 均匀抽样or非均匀抽样?

#### 均匀抽样和非均抽采样

均匀抽样：对冷门物品不公平

- 正样本大多是热门物品。
- 如果均匀抽样产生负样本，负样本大多是冷门物品。

非均抽采样：目的是打压热门物品

- 负样本抽样概率与热门程度（点击次数）正相关。
- 抽样概率正比于$(点击次数)^{0.75}$，其中0.75是个经验值。

### Batch内负样本

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309104632.png)

一个batch 内有 n个正样本，一个用户和n－1个物品组成负样本。这个 batch 内一共有 n(n － 1) 个负样本。这些负样本都是简单负样本。（因为第一个用户不喜欢第二个物品。）

一个物品出现在 batch 内的概率正比于点击次数。

物品成为负样本的概率本该是正比于$(点击次数)^0.75$，但在这里是正比于点击次数。

热门物品成为负样本的概率过大。

物品$i$被抽样到的概率$p_i$正比于点击次数。

预估用户对物品$i$的兴趣$cos(a, b_i)$

根据YouTube论文的建议，做训练的时候，可以把$cos(a, b_i)$调整为$cos(a,b_i) - logp_i$，这样可以纠偏，避免过度打压热门物品。训练结束之后，在线上召回时，还是使用原本的余弦相似度$cos(a, b_i)$。

### 困难负样本

- 被粗排淘汰的物品（比较困难）
- 精排分数靠后的物品（非常困难）

对正负样本做二元分类：
- 全体物品（简单）分类准确率高。
- 被粗排淘汰的物品（比较困难）容易分错。
- 精排分数靠后的物品（非常困难）更容易分错。


### 训练数据

- 混合几种负样本。
- 50%的负样本是全体物品（简单负样本）
- 50%的负样本是没通过排序的物品（困难负样本）

### 常见的错误

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250216103942.png)

### 选择负样本的原理

召回的目标：快速找到用户可能感兴趣的物品。

全体物品（easy）：绝大多数是用户根本不感兴趣的。

被排序淘汰（hard）：用户可能感兴趣’但是不够感兴趣。

有曝光没点击（没用）：用户感兴趣，可能碰巧没有点击。**有曝光没点击（没用）的物品可以作为排序的负样本，不能作为召回的负样本。**

## 双塔模型的线上召回

这节课讲解双塔模型（two-tower，也叫 DSSM）的线上服务和模型更新。  
  
在开始线上服务之前，需要把物品向量存储到Milvus、Faiss、HnswLib这类向量数据库，供最近邻查找（KNN 或 ANN）。当用户发起推荐请求时，用户塔用用户ID和用户画像现算一个用户向量，作为query，去向量数据库中做最近邻查找。  
  
模型需要定期做更新，分为全量更新（天级别）和增量更新（实时）。全量更新会训练整个模型，包括embedding和全连接层。而增量更新只需要训练embedding层。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309111327.png)

离线存储：把物品向量b 存入向量数据库。

1. 完成训练之后，用物品塔计算每个物品的特征向量b； 
2. 把几亿个物品向量b存入向量数据库（比如Milvus、Faiss 、HnswLib）
3. 向量数据库建索引，以便加速最近邻查找。

线上召回：查找用户最感兴趣的k个物品。

1. 给定用户ID和画像，线上用神经网络算用户向量a。
2. 最近邻查找：把向量a作为query，调用向量数据库做最近邻查找。返回余弦相似度最大的k个物品，作为召回结果。

思考问题：事先存储物品向量b，线上现算用户向量a，why？

- 每做一次召回，用到一个用户向量a，几亿物品向量b。（线上算物品向量的代价过大。）
- 用户兴趣动态变化，而物品特征相对稳定。（可以离线存储用户向量，但不利于推荐效果。)

## 模型更新

### 全量更新

全量更新：今天凌晨，用昨天全天的数据训练模型。

- 在昨天模型参数的基础上做训练。（不是随机初始化）
- 用昨天的数据，训练1 epoch，即每天数据只用一遍。
- 发布新的用户塔神经网络和物品向量，供线上召回使用。
- 全量更新对数据流、系统的要求比较低。

###  增量更新

增量更新：做 online learning 更新模型参数

- 用户兴趣会随时发生变化。
- 实时收集线上数据，做流式处理，生成TFRecord文件
- 对模型做 online learning，增量更新 ID Embedding 参数。（不更新神经网络其他部分的参数。）
- 发布用户IDEmbedding，供用户塔在线上计算用户向量。

### 全量更新 VS 增量更新

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250216105707.png)

思考问题：能否只做增量更新，不做全量更新？

只做增量更新，不做全量更新的方式推荐效果较差。

- 小时级数据有偏；分钟级数据偏差更大
- 全量更新：random shuffle一天的数据，做 1 epoch 训练，来消除偏差。
- 增量更新：按照数据从早到晚的顺序；做1 epoch 训练
- 随机打乱优于按顺序排列数据，全量训练优于增量训练。

## 双塔模型+自监督学习

前几节课详细讲解了双塔模型。这节课介绍一种改进双塔模型的方法，叫做自监督学习（self-supervised learning），用在双塔模型上可以提升业务指标。这种方法由谷歌在2021年提出，工业界（包括小红书）普遍验证有效。

参考文献：
- Tiansheng Yao et al. Self-supervised Learning for Large-scale Item Recommendations. In CIKM, 2021.
### 双塔模型的问题

推荐系统的头部效应严重：
- 少部分物品占据大部分点击。
- 大部分物品的点击次数不高。

高点击物品的表征学得好，长尾物品的表征学得不好。

自监督学习：做data augmentation，更好地学习长尾物品的向量表征。

训练双塔模型时，batch内负样本打压热门物品，需要纠偏。

### 自监督学习

物品$i$的两个向量表征$b_i'$;和$b_i''$有较高的相似度，物品$i$和$j$的向量表征$b_i'$和$b_j''$有较低的相似度，鼓励 $cos(b_i,b_i'')$尽量大$cos(b_i',b_j'')$尽量小。

常用方法：
- 特征变换：Random Mask
- 特征变换：Dropout（仅对多值离散特征生效）
- 特征变换：互补特征（complementary）
- 特征变换：Mask一组关联的特征
#### 特征变换Random Mask

随机选一些离散特征（比如类目），把它们遮住。

例：某物品的类目特征是U={数码,摄影}，Mask后的类目特征是U'={default}。

#### 特征变换：Dropout（仅对多值离散特征生效）

一个物品可以有多个类目，那么类目是一个多值离散特征。

Dropout：随机丢弃特征中50%的值。

例：某物品的类目特征是U={美妆,摄影}。Dropout 后的类目特征是U'={美妆}。

#### 特征变换：互补特征（complementary）

假设物品一共有4种特征：ID，类目，关键词，城市

随机分成两组：{ID，关键词}和{类目，城市}

{ID，default，关键词，default}→物品表征

{default，类目，default，城市}→物品表征

#### 特征变换：Mask一组关联的特征

受众性别：U={男,女,中性}

类目：V ={美妆,数码,足球,摄影,科技,··}

u=女和v=美妆同时出现的概率$p(u,v)$大。

u=女和v=数码同时出现的概率$p(u,v)$小。

$p(u)$：某特征取值为u的概率。

$p(u,v)$：某特征取值为u，另一个特征取值为v，同时发生的概率。

离线计算特征两两之间的关联，用互信息（mutual information）衡量。

设一共有k种特征。离线计算特征两两之间MI，得到 $k\times k$ 的矩阵。随机选一个特征作为种子，找到种子最相关的$k/2$种特征。Mask 种子及其相关的$k/2$种特征，保留其余的$k/2$种特征。

好处：比 random mask、dropout、互补特征等方法效果更好。

坏处：方法复杂，实现的难度大，不容易维护。

### 训练模型

从全体物品中均匀抽样，得到m个物品；作为一个 batch。做两类特征变换，物品塔输出两组向量。计算第$i$个物品的损失函数。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309113955.png)

构建自监督学习的损失函数，做梯度下降，减小自监督学习的损失。

# Deep Retrieval

经典的双塔模型把用户、物品表示为向量，线上做最近邻查找。

Deep Retrieval[1]把物品表征为路径（path），线上查找用户最匹配的路径。

Deep Retrieval 类似于阿里的 TDM[2]。

参考文献：
1. Weihao Gao et al. Learning A Retrievable Structure for Large-Scale Recommendations. In CIKM, 2021.
2.  Han Zhu et al. Learning Tree-based Deep Model for Recommender Systems. In KDD, 2018.

## Outline

1. 索引：
	- 路径→List<物品>
	- 物品 → List<路径>
2. 预估模型：神经网络预估用户对路径的兴趣
3. 线上召回：用户→路径→物品。 
4. 训练：
	- 学习神经网络参数。
	- 学习物品表征（物品→路径）


# 其他召回通道

## 地理位置召回

### GeoHash召回

用户可能对附近发生的事情感兴趣。

GeoHash是对经纬度的编码，代表地图上一个长方形区域。

索引：GeoHash->优质笔记列表（按时间倒排）。

这条召回通道没有个性化处理。

根据用户定位的GeoHash，取回该地点最新的 k 篇优质笔记。

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250309101152.png)

### 同城召回

用户可能对同城发生的事感兴趣。

索引：城市→优质笔记列表（按时间倒排）

这条召回通道也没有个性化处理。

## 作者召回
### 关注作者召回

用户对关注的作者发布的笔记感兴趣。

索引：
- 用户→ 关注的作者
- 作者 →发布的笔记

召回：用户→关注的作者→最新的笔记

### 有交互的作者召回

如果用户对某笔记感兴趣（点赞、收藏、转发），那么用户可能对该作者的其他笔记感兴趣。

索引：用户→有交互的作者

召回：用户→有交互的作者→最新的笔记

### 相似作者召回

如果用户喜欢某作者，那么用户喜欢相似的作者。

索引：作者→相似作者（k 个作者）

召回：用户→感兴趣的作者（n 个作者）→相似作者（nk 个作者）→最新的笔记（nk 篇笔记）
## 缓存召回

想法：复用前n次推荐精排的结果

背景：
- 精排输出几百篇笔记，送入重排。
- 重排做多样性抽样，选出几十篇。
- 精排结果一大半没有曝光，被浪费。

精排前50，但是没有曝光的，缓存起来，作为一条召回通道。

### 退场机制

缓存大小固定，需要退场机制。

一旦笔记成功曝光，就从缓存退场。

如果超出缓存大小，就移除最先进入缓存的笔记。

笔记最多被召回10次，达到10次就退场。

每篇笔记最多保存3天，达到3天就退场。

# 曝光过滤&Bloom Filter

## 曝光过滤问题

如果用户看过某个物品，则不再把该物品曝光给该用户。

对于每个用户，记录已经曝光给他的物品。（小红书只召回1个月以内的笔记，因此只需要记录每个用户最近1个月的曝光历史。）

对于每个召回的物品，判断它是否已经给该用户曝光过，排除掉曾经曝光过的物品。

一位用户看过$n$个物品，本次召回$r$个物品，如果暴力对比，需要$O(nr)$的时间。

## Bloom Filter

Bloom filter 判断一个物品ID是否在已曝光的物品集合中。

如果判断为no，那么该物品一定不在集合中。

如果判断为yes，那么该物品很可能在集合中。（可能误伤，错误判断未曝光物品为已曝光，将其过滤掉。）

Bloom filter 把物品集合表征为一个m 维二进制向量。

每个用户有一个曝光物品的集合，表征为一个向量，需要m bit的存储。

Bloom filter 有k个哈希函数，每个哈希函数把物品 ID 映射成介于0和m一1之间的整数。

参考文献：
- Burton H. Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 1970.

### 架构图

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250308112810.png)

曝光物品集合大小为n，二进制向量维度为m，使用k个哈希函数。

Bloom filter 误伤的概率为 $\delta ≈((1-exp(-\frac{kn}{m}))^k$

- n越大，向量中的1越多，误伤概率越大。（未曝光物品的 k 个位置恰好都是1的概率大。）
- m越大，向量越长，越不容易发生哈希碰撞。
- k太大、太小都不好，k有最优取值。

### 曝光过滤的链路

![](https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost04/img20250308113105.png)

### Bloom Filter的缺点

Bloom filter 把物品的集合表示成一个二进制向量。

每往集合中添加一个物品，只需要把向量k个位置的元素置为1。（如果原本就是1，则不变。）

Bloom filter只支持添加物品，不支持删除物品。从集合中移除物品，无法消除它对向量的影响。

每天都需要从物品集合中移除年龄大于1个月的物品。（超龄物品不可能被召回，没必要把它们记录在 Bloom filter，降低n可以降低误伤率。）


